---
title: "Thriving in tech's AI era"
description: 'Doing everything right and still uncertain. Why the "AI will replace us" narrative misses the point—and what actually matters.'
pubDate: 2026-02-06
tags: ['ai', 'career', 'tech', 'personal']
---

There's a strange moment I keep returning to: I'm using AI to write about AI's impact on tech jobs -- The irony is not lost on me.

---

I'm doing everything the advice says to do. I'm embracing LLMs. I've shifted how I work — treating AI like a collaborative partner, not a threat. I integrate it into daily workflows. I experiment. I adapt. And somehow, I still feel uncertain about what comes next.

That feeling is everywhere in tech right now. Layoffs. Breakthroughs in agentic systems. The sense that the ground is shifting faster than we can keep up. And the constant, nagging question: _What if I'm obsolete?_

The question assumes something I don't think is true.

## The replacement narrative is too simple

"AI will replace developers" is the kind of statement that sounds deep until you sit with it for a minute. It collapses under its own oversimplification.

Here's what actually happened: Spreadsheets didn't eliminate accountants. They eliminated tedium. Accountants stopped doing manual calculation and started doing strategic financial analysis. The _work_ changed. The _people_ adapted or didn't, but the profession didn't disappear — it evolved.

Calculators didn't kill mathematicians. Version control didn't kill programmers. Cloud platforms didn't eliminate infrastructure engineers. In each case, the tools eliminated the manual work and elevated what humans focused on.

AI is the same pattern. It's not that coding will disappear; it's that coding as pure syntax-generation is already becoming a non-differentiator. What you'll compete on is the part that was always harder: understanding messy business problems, translating between technical and non-technical worlds, making judgment calls with incomplete information, and knowing when _not_ to ship something.

The real threat isn't AI. It's stagnation. It's the engineer who refuses to use LLMs the same way it would've been the engineer who refused to learn Git in 2008 or cloud platforms in 2015. Technology adoption has never been optional in tech. It's just accelerated now.

## The game isn't changed — it's reframed

You're not competing with AI. You're competing with the engineer next to you who uses AI better than you do.

That's a different question. And it's more practical.

When I use an LLM to scaffold boilerplate, think through architecture, or spot bugs in a code review, I'm not being replaced — I'm being amplified. I'm 10x faster at the parts that were slow, which means I have more time for the parts that matter: understanding the problem, making trade-offs, building things that actually solve the right problem instead of the obvious one.

Your colleagues who aren't touching AI? They're not safer. They're accumulating technical debt in their skill sets. In a few years, not knowing how to work with these tools will be like not knowing how to use GitHub. Possible, sure. But limiting.

## What humans will still have

Here's what AI can't do (yet, and maybe ever):

- Understand a business problem well enough to ask the right questions before building
- Translate between a VP's vague handwaving and actual technical requirements
- Make judgment calls when the spec is incomplete or the tradeoffs are unclear
- Say "we shouldn't build this" when the answer isn't technical
- Build trust and context with a team over months and years
- Carry accountability for decisions
- Wake up at 2 AM because something's wrong, and you care enough to fix it

That stuff is what makes you valuable. AI doesn't change that. It just makes you more efficient at everything else.

## The productivity paradox

Here's the dissonance I sit with: Being 10x more productive doesn't guarantee job security in a downturn. That's real. A company with 100 developers doing the work of 150 might not need 100 developers anymore—they might need 50. Being the best 50 is better than being the worst 50, but it doesn't guarantee anything.

But here's the flip side: Being 10x more productive does position you better for the _next_ opportunity. It makes you indispensable in the moments that matter. It builds a portfolio of work that speaks louder than a résumé.

I can't promise you security. No one honest can. But I can tell you that adaptability compounds. The people who thrive aren't the ones who predicted the future correctly — they're the ones who moved fast enough to adjust when their prediction was wrong.

## What actually matters

This isn't about survival. It's about opportunity.

The tech industry has always been about continuous learning. Uncertainty has always been baked in. Moore's Law, the cloud transition, mobile, containerisation — all of these felt uncertain when they arrived. And every time, the people who thrived were curious enough to experiment and pragmatic enough to adapt.

AI is just the current cycle.

So here's what I actually do when I feel that uncertainty creeping in:

**Start small.** Pick one workflow where an AI tool would save time — code review, architecture sketching, documentation, debugging. Just one. Use it for a week.

**Share what you learn.** Your curiosity is your leverage. Teaching colleagues what you're learning makes your value visible and builds your reputation as someone moving forward, not standing still.

**Focus on what you can't outsource.** Judgment, creativity, decision-making, relationships, accountability. These are the skills that compound and the ones AI is worst at.

**Stay honest about limitations.** Using AI doesn't mean you stop thinking. It means you're thinking at a higher level. The engineers who struggle with LLMs are the ones who treat them as oracles instead of tools — who don't verify outputs, don't understand the limitations, don't own the code.

## The strange part

What's actually unsettling isn't the fear that I'm becoming obsolete. It's that I'm not sure _what_ I'm optimising for anymore.

In previous tech transitions, it was clear: learn this new framework, master this tool, build on this platform. Here, the target is moving. Agentic systems are getting better. The capabilities changing monthly. There's no "I'll master AI" endpoint — it's an ongoing calibration.

That's uncomfortable. It's also kind of what tech has always been.

## Uncertainty is just the tax

If you're in tech, and you're not uncertain right now, you're either not paying attention or you're lying. The people I respect most are the ones admitting it — the ones experimenting anyway, shipping things even though the rules might change, staying curious instead of assuming they have the answers.

Your willingness to adapt is the skill that matters. Not your perfect prediction of the future. Not your collection of certifications. Not your seniority or your GitHub stars. It's whether you can look at something new, figure out how it changes your work, and move forward.

The future belongs to the curious, not the perfect. And that's a game we can all compete in.

What's one way you'll experiment with AI this week? Not someday. This week. Small thing. Doesn't matter if it fails.

That's how you stay ahead. Not by being right. By being willing to move.
